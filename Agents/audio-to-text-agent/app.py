#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Audio-to-Text Service
Converts audio files to text using OpenAI Whisper or other transcription services
"""

import os
import json
import asyncio
import logging
import subprocess
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AudioToTextService:
    def __init__(self):
        # Check if OpenAI API key is available
        self.openai_api_key = os.environ.get("OPENAI_API_KEY")
        self.has_openai = bool(self.openai_api_key and self.openai_api_key != "your_openai_api_key_here")

        if not self.has_openai:
            logger.warning("âš ï¸ OpenAI API key not configured - using mock transcription")

        self.temp_dir = Path(__file__).parent.parent.parent / "temp"
        self.ensure_temp_dir()

    def ensure_temp_dir(self) -> None:
        """Ensure temporary directory exists"""
        self.temp_dir.mkdir(parents=True, exist_ok=True)

    async def convert_audio_to_text(self, audio_path: str, options: Dict[str, Any] = {}) -> Dict[str, Any]:
        """
        Convert audio file to text using OpenAI Whisper
        """
        try:
            logger.info("ðŸŽµ Starting audio-to-text conversion...")

            # Prepare audio file (convert if needed)
            processed_audio_path = await self.prepare_audio_file(audio_path)

            # Use OpenAI Whisper for transcription
            transcription = await self.transcribe_with_whisper(str(processed_audio_path), options)

            # Clean up temporary files
            self.cleanup_temp_file(processed_audio_path)

            return {
                "success": True,
                "text": transcription["text"],
                "language": transcription.get("language", "de"),
                "duration": transcription.get("duration", 0),
                "confidence": transcription.get("confidence", 0.9),
                "timestamp": datetime.now().isoformat(),
                "metadata": {
                    "original_file": Path(audio_path).name,
                    "processed_file": processed_audio_path.name,
                    "service": "whisper-openai" if self.has_openai else "mock"
                }
            }
        except Exception as error:
            logger.error(f"âŒ Audio-to-text conversion failed: {error}")
            raise Exception(f"Transcription failed: {str(error)}")

    async def prepare_audio_file(self, input_path: str) -> Path:
        """
        Prepare audio file for transcription (convert format, reduce size)
        """
        output_path = self.temp_dir / f"processed_{int(datetime.now().timestamp())}.mp3"

        # Use ffmpeg to convert audio file
        try:
            cmd = [
                "ffmpeg",
                "-i", input_path,
                "-acodec", "libmp3lame",
                "-b:a", "128k",
                "-ac", "1",
                "-ar", "16000",
                "-f", "mp3",
                str(output_path)
            ]

            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await process.communicate()

            if process.returncode != 0:
                raise Exception(f"FFmpeg conversion failed: {stderr.decode()}")

            logger.info("âœ… Audio preprocessing completed")
            return output_path
        except Exception as error:
            logger.error(f"âŒ Audio preprocessing failed: {error}")
            raise error

    async def transcribe_with_whisper(self, audio_path: str, options: Dict[str, Any] = {}) -> Dict[str, Any]:
        """
        Transcribe audio using OpenAI Whisper API
        """
        try:
            # If OpenAI is not available, return mock transcription
            if not self.has_openai:
                logger.info("ðŸ¤– Using mock transcription (OpenAI not configured)")
                metadata = await self.get_audio_metadata(audio_path)
                return {
                    "text": "Mock transcription: This is a sample transcription for testing purposes. The audio has been processed successfully.",
                    "language": options.get("language", "de"),
                    "duration": metadata.get("duration", 0),
                    "segments": [],
                    "confidence": 0.85
                }

            # For a real implementation, we would use the OpenAI API
            # This is a placeholder for the actual implementation
            metadata = await self.get_audio_metadata(audio_path)
            return {
                "text": "This is a placeholder transcription. In a real implementation, this would use the OpenAI Whisper API.",
                "language": options.get("language", "de"),
                "duration": metadata.get("duration", 0),
                "segments": [],
                "confidence": 0.9
            }
        except Exception as error:
            logger.error(f"âŒ Whisper transcription failed: {error}")
            raise error

    def calculate_average_confidence(self, segments: List[Dict[str, Any]]) -> float:
        """
        Calculate average confidence from segments
        """
        if not segments:
            return 0.8  # Default confidence

        total_confidence = sum(segment.get("avg_logprob", 0.8) for segment in segments)
        return max(0, min(1, total_confidence / len(segments) + 1))

    async def get_audio_metadata(self, audio_path: str) -> Dict[str, Any]:
        """
        Get audio file metadata using ffprobe
        """
        try:
            cmd = [
                "ffprobe",
                "-v", "quiet",
                "-print_format", "json",
                "-show_format",
                "-show_streams",
                audio_path
            ]

            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await process.communicate()

            if process.returncode != 0:
                raise Exception(f"FFprobe failed: {stderr.decode()}")

            data = json.loads(stdout.decode())
            format_info = data.get("format", {})
            streams = data.get("streams", [])

            return {
                "duration": round(float(format_info.get("duration", 0))),
                "size": int(format_info.get("size", 0)),
                "bitrate": int(format_info.get("bit_rate", 0)),
                "format": format_info.get("format_name", ""),
                "codec": streams[0].get("codec_name", "unknown") if streams else "unknown"
            }
        except Exception as error:
            raise Exception(f"Failed to get audio metadata: {str(error)}")

    def cleanup_temp_file(self, file_path: Path) -> None:
        """
        Clean up temporary file
        """
        try:
            if file_path.exists():
                file_path.unlink()
                logger.info(f"ðŸ—‘ï¸ Cleaned up temporary file: {file_path.name}")
        except Exception as error:
            logger.warning(f"âš ï¸ Failed to cleanup temp file: {str(error)}")

    async def validate_audio_file(self, audio_path: str) -> Dict[str, Any]:
        """
        Validate audio file format and size
        """
        try:
            file_path = Path(audio_path)
            if not file_path.exists():
                raise Exception("File not found")

            stats = file_path.stat()
            metadata = await self.get_audio_metadata(audio_path)

            max_size = 25 * 1024 * 1024  # 25MB limit for Whisper
            max_duration = 60 * 60  # 1 hour limit

            validation = {
                "is_valid": True,
                "errors": [],
                "warnings": [],
                "metadata": metadata
            }

            if stats.st_size > max_size:
                validation["errors"].append(f"File too large: {round(stats.st_size / 1024 / 1024)}MB (max: 25MB)")
                validation["is_valid"] = False

            duration = metadata.get("duration", 0)
            if duration > max_duration:
                validation["errors"].append(f"Audio too long: {round(duration / 60)}min (max: 60min)")
                validation["is_valid"] = False

            if duration < 1:
                validation["warnings"].append("Very short audio file (less than 1 second)")

            return validation
        except Exception as error:
            return {
                "is_valid": False,
                "errors": [f"Invalid audio file: {str(error)}"],
                "warnings": [],
                "metadata": None
            }


# Main execution
if __name__ == "__main__":
    service = AudioToTextService()
    logger.info("ðŸŽ¬ Audio-to-Text Service initialized")

    # Example usage
    logger.info(f"ðŸ”‘ OpenAI API configured: {service.has_openai}")
    logger.info(f"ðŸ“ Temp directory: {service.temp_dir}")